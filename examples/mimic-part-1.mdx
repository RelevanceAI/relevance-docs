---
title: 'Teach LLMs to mimic your style - Part 1'
sidebarTitle: 'Sales response automation'
description: 'Use few-shot prompting to teach your LLM to mimic your style'
---

In this guide we'll explore how you can enhance your LLM's performance and teach it to mimic your style. We're diving into the world of few-shot prompting with large language models (LLMs), sharing a technique that allows LLMs to mimic your style based on large datasets. Let's get started!

<iframe width="560" height="315" src="https://www.youtube.com/embed/u2B_zveY_9c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## **Few-shot prompting basics**

Few-shot prompting is a technique that feeds an LLM with some example data on how you want the response to be made. The LLM then generates a response that mimics the given examples. 

This technique can significantly enhance the performance of your LLM. LLMs are trained on a vast amount of training data, both of good and bad quality. Therefore, we aim to narrow the LLMs focus down to the specific knowledge and style that we prefer. 

## A real-life example: sales response automation

Let's take a real-life example. Suppose you want to create a sales automation tool that can respond to emails and LinkedIn messages automatically. 

You can use few-shot prompting to train your LLM to generate responses that align with your style and meet your specific rules and objectives.

For instance, LinkedIn messages tend to be shorter and more specific. Few-shot prompting can help you adapt your LLM's responses to these different environments, ensuring that your messages are always on point.

**Customise the system prompt**

You can also customise the "system prompt" under "advanced options" with something like:

`You are a sales representative for relevant AI. Your goal is to reply to emails being professional while trying to book a meeting.`

<Tip>Customizing the prompts and including examples specific to your data context can enhance performance.</Tip>

**Add examples to your LLM prompt**

We aim to incorporate messages that some of our prospects have previously sent us, along with our responses to them. These will constitute the prospect-Relevance AI LinkedIn message pairs, serving as examples. 

The more examples we include, the better performance we can anticipate from the LLM.

![Prompt with examples.png](/images/prompt-with-examples.png)

As we can see in the result it's now mimicking our style, the length and the tone of voice. 

## Taking a step further: using a training database

We've already started altering how the LLM processes our messages based on the examples we provide. But what if we go a few steps further? 

By using a database of responses and replies that have proven effective in the past, you can train your LLM to generate similar responses. 

**Add ‚ÄòVector similarity search‚Äô step**

Let‚Äôs create our own few-shot prompting technique based on an entire dataset. This can be achieved by using a search step to find the most similar past response to the current input.

![vector search step.png](/images/vector-search-step.png)

1. First we need to select the ‚Äòsales responses‚Äô data set. 

<aside>
üí° In the next part of this series, we'll walk you through the process of creating your own dataset.

</aside>

1. Then we input our search query. This will be the sales response parameter, `{{response}}` that we want the LLM to provide an answer to, in a way that mimics our style.
2. We paste in the name of the vector field. In this case it‚Äôs `prospect-reply_openai_vector_` 

<aside>
üí° In the next part of this series, we'll guide you through the process of vectorizing your dataset and identifying the vector field's name.

</aside>

1. Next, we choose the model. It's important to select the model that was used to vectorise the dataset. In this instance, it's the Open AI model, `text-embedding-ada-002`.

Once you've done this, you can run the step to get a bunch of results with responses that we've previously received and that are most similar to your input.

**Add ‚ÄòTruncate text‚Äô step**

We aim to feed the results of the ‚ÄòVector similarity search‚Äô into our LLM prompt, so our LLM can generate a response to the sales message based on those shortlisted examples.

To achieve this, we may need to increase the number of results from the vector search. This can be done by increasing the ‚Äúpage size‚Äù in the ‚ÄòVector similarity search‚Äô step to, let's say to 30.

Next, we need to add another step to truncate the results. This allows us to specify an array, which is derived from the result of our previous Vector Search step, and limit the size of objects within the result to a certain number of tokens. Tokens are the limit of how large language models count the length of words. For instance, in this case, we can set it to 2000.

If we execute the ‚ÄòTruncate text‚Äô step, we'll see that it ensures we never have more than 2000 tokens worth of data in the LLM prompt.

![Truncate text.png](/images/truncate-text.png)

**Feeding the Vector search results into your LLM prompt**

Instead of giving manual examples, we can now include the output from the chunks of the previous 'Truncate text' step in our LLM prompt.

Our final LLM prompt: 

```
Based on the responses create a response for the prospect. The following data shows examples of the prospect sending a message in "prospect-reply" and the Relevance AI sales rep replying in "relevance-reply".

{{ steps.truncate_text.output.chunks }}

RESPONSE: {{ params.response }}

RELEVANCE AI REPLY:
```

**Wrapping up**

From the final results, it's clear that the LLM output now includes important details from the training dataset, which the LLM now mimics. This could be knowledge and context about our product, the specific way we asks questions, call to actions, and so on.

You've now learned how to use few-shot prompting to teach your LLM to mimic your style. The key to success with few-shot prompting is experimentation. So we advise you to try out different techniques and see what works best for you.

In the next tutorial, we'll delve deeper into how to prepare your dataset for few-shot prompting. Stay tuned!